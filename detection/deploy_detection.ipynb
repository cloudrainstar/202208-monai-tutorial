{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fb4cdae",
   "metadata": {},
   "source": [
    "# MONAI Deploy pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834eeb5",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f473e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting monai-deploy-app-sdk\n",
      "  Downloading monai_deploy_app_sdk-0.4.0-py3-none-any.whl (162 kB)\n",
      "\u001b[K     |████████████████████████████████| 162 kB 20.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.4 in /opt/conda/lib/python3.8/site-packages (from monai-deploy-app-sdk) (2.6.3)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.8/site-packages (from monai-deploy-app-sdk) (1.22.4)\n",
      "Collecting typeguard>=2.12.1\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: colorama>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from monai-deploy-app-sdk) (0.4.4)\n",
      "Installing collected packages: typeguard, monai-deploy-app-sdk\n",
      "Successfully installed monai-deploy-app-sdk-0.4.0 typeguard-2.13.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade monai-deploy-app-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc8fcbc",
   "metadata": {},
   "source": [
    "# Import Dependencies\n",
    "Here, we need to import monai deploy classes, as well as the transforms that we used from MONAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ecc1d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import monai.deploy.core as md  # 'md' stands for MONAI Deploy (or can use 'core' instead)\n",
    "from monai.deploy.core import (\n",
    "    Application,\n",
    "    DataPath,\n",
    "    ExecutionContext,\n",
    "    InputContext,\n",
    "    IOType,\n",
    "    Operator,\n",
    "    OutputContext,\n",
    ")\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    BoundingRectd,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    Lambdad,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.apps.detection.utils.anchor_utils import AnchorGeneratorWithAnchorShape\n",
    "from monai.apps.detection.metrics.coco import COCOMetric\n",
    "from monai.apps.detection.metrics.matching import matching_batch\n",
    "from monai.apps.detection.networks.retinanet_detector import RetinaNetDetector\n",
    "from monai.apps.detection.networks.retinanet_network import (\n",
    "    RetinaNet,\n",
    "    resnet_fpn_feature_extractor,\n",
    ")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df904577",
   "metadata": {},
   "source": [
    "# Creating our operator\n",
    "Here we define our operator as follows:\n",
    "1. First we define an input of type DataPath from DISK.\n",
    "2. Next, we define an output of type DataPath from DISK.\n",
    "3. Third, we ensure that monai is a dependency that needs to be installed.\n",
    "4. Then, we define the class, inheriting the Operator class from MONAI Deploy\n",
    "5. Then we add a property called transform which will do the validation style transforms that we defined in the training module.\n",
    "6. We then write the compute function, which should consist of getting the path from the input context, using transform on the path, converting the output to an output tensor that is then put on the GPU, and lastly the model is used to perform a forward pass with the image tensor.\n",
    "7. Lastly, the results are postprocessed into the classes using argmax and the results are saved to output.json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d162bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@md.input(\"image\", DataPath, IOType.DISK)\n",
    "@md.output(\"output\", DataPath, IOType.DISK)\n",
    "@md.env(pip_packages=[\"monai\"])\n",
    "class SpleenDetectorOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        test_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\"]),\n",
    "                EnsureChannelFirstd(keys=[\"image\"]),\n",
    "                EnsureTyped(keys=[\"image\"], dtype=torch.float32),\n",
    "                ScaleIntensityRanged(\n",
    "                    keys=[\"image\"], a_min=-57, a_max=164,\n",
    "                    b_min=0.0, b_max=1.0, clip=True,\n",
    "                ),\n",
    "                CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "                Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "                Spacingd(keys=[\"image\"], pixdim=(\n",
    "                    1.5, 1.5, 2.0), mode=(\"bilinear\")),\n",
    "            ]\n",
    "        )\n",
    "        return test_transforms\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "        \n",
    "        input_path = op_input.get().path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image_tensor = self.transform({\"image\": input_path})  # Load path as dict\n",
    "        image_tensor = torch.tensor(image_tensor[\"image\"].array)  # Get just the image for input\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = [image_tensor.to(device)]\n",
    "\n",
    "        ### Build Anchor Generator\n",
    "        anchor_generator = AnchorGeneratorWithAnchorShape(\n",
    "            feature_map_scales=[2**l for l in range(len([1,2]) + 1)],\n",
    "            base_anchor_shapes=[[6,8,4],[8,6,5],[10,10,6]],\n",
    "        )\n",
    "        \n",
    "        ### Build Model\n",
    "        model = context.models.get()  # get a TorchScriptModel object\n",
    "        model.predictor = torch.jit.load(model.path, map_location=device).eval()\n",
    "        net = model.predictor\n",
    "        \n",
    "        ### Build Detector\n",
    "        detector = RetinaNetDetector(\n",
    "            network=net, anchor_generator=anchor_generator, debug=False\n",
    "        ).to(device)\n",
    "\n",
    "        detector.set_target_keys(box_key=\"label_box\", label_key=\"label_class\")\n",
    "\n",
    "        # set validation components\n",
    "        detector.set_box_selector_parameters(\n",
    "            score_thresh=0.02,\n",
    "            topk_candidates_per_level=1000,\n",
    "            nms_thresh=0.22,\n",
    "            detections_per_img=100,\n",
    "        )\n",
    "        detector.set_sliding_window_inferer(\n",
    "            roi_size=[512,512,208],\n",
    "            overlap=0.25,\n",
    "            sw_batch_size=1,\n",
    "            mode=\"constant\",\n",
    "            device=\"cpu\",\n",
    "        )\n",
    "        \n",
    "        detector.eval()\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                val_outputs_all = detector(image_tensor, use_inferer=True)\n",
    "\n",
    "        pred_boxes=[\n",
    "            val_data_i[detector.target_box_key].cpu().detach().numpy().tolist()\n",
    "            for val_data_i in val_outputs_all\n",
    "        ],\n",
    "        pred_classes=[\n",
    "            val_data_i[detector.target_label_key].cpu().detach().numpy().tolist()\n",
    "            for val_data_i in val_outputs_all\n",
    "        ],\n",
    "        pred_scores=[\n",
    "            val_data_i[detector.pred_score_key].cpu().detach().numpy().tolist()\n",
    "            for val_data_i in val_outputs_all\n",
    "        ],\n",
    "        print(pred_boxes, pred_classes, pred_scores)\n",
    "        result = {\"boxes\": pred_boxes, \"classes\": pred_classes, \"scores\": pred_scores}\n",
    "\n",
    "        # Get output (folder) path and create the folder if not exists\n",
    "        output_folder = op_output.get().path\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Write result to \"output.json\"\n",
    "        output_path = output_folder / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70976864",
   "metadata": {},
   "source": [
    "# Creating our application\n",
    "In this section, all the operators that are defined should be included. Here, we only used one operator, so we will use the add_operator function to add our operator into the application function. Notice here that you can also define the number of cpu, gpu and memory that are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7b6f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "@md.resource(cpu=2, gpu=1, memory=\"8Gi\")\n",
    "class App(Application):\n",
    "    \"\"\"Application class for the Spleen detector.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        classifier_op = SpleenDetectorOperator()\n",
    "\n",
    "        self.add_operator(classifier_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fd2a1",
   "metadata": {},
   "source": [
    "# Testing our application\n",
    "\n",
    "In order to test our application, we will point \"test_input_path\" to a jpeg file in our test folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c90ce89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input file path: ./Task09_Spleen/imagesTs/spleen_1.nii.gz\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"./\"\n",
    "data_dir = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "test_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTs\", \"*.nii.gz\")))\n",
    "data_dicts = [\n",
    "    {\"image\": image_name}\n",
    "    for image_name in test_images\n",
    "]\n",
    "test_input_path = data_dicts[0][\"image\"]\n",
    "print(f\"Test input file path: {test_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08cf2d4",
   "metadata": {},
   "source": [
    "Next, we instantiate the App class, and then perform run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b4a4a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = App()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9d54848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mGoing to initiate execution of operator SpleenDetectorOperator\u001b[39m\n",
      "\u001b[32mExecuting operator SpleenDetectorOperator \u001b[33m(Process ID: 5894, Operator ID: d2924a33-5ea5-42ee-9b12-26cd3686f279)\u001b[39m\n",
      "([[[21.58724594116211, 60.32127380371094, 33.97724151611328, 75.53152465820312, 108.71205139160156, 62.45012664794922], [29.138856887817383, 57.99709701538086, 45.1968994140625, 66.86248779296875, 83.99801635742188, 66.1964111328125], [21.605960845947266, 48.43174743652344, 49.73490524291992, 75.6953125, 96.08973693847656, 78.13142395019531], [35.06386947631836, 68.13758087158203, 40.05929183959961, 60.62265396118164, 100.37023162841797, 56.25345230102539], [45.2677001953125, 71.50562286376953, 45.317298889160156, 82.5245361328125, 97.23815155029297, 66.2081527709961], [28.44527244567871, 57.32223892211914, 29.66332244873047, 66.66019439697266, 83.91702270507812, 51.12281036376953], [0.0, 14.650421142578125, 20.98767852783203, 38.73200607299805, 76.86129760742188, 43.37999725341797], [0.0, 43.802040100097656, 18.751644134521484, 31.445295333862305, 60.979209899902344, 43.825016021728516]]],) ([[0, 0, 0, 0, 0, 0, 0, 0]],) ([[0.28776782751083374, 0.09653531759977341, 0.07356304675340652, 0.03138042986392975, 0.026810195297002792, 0.022586042061448097, 0.02136888913810253, 0.020567094907164574]],)\n",
      "\u001b[34mDone performing execution of operator SpleenDetectorOperator\n",
      "\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "app.run(input=test_input_path, output=\"output\", model=\"classifier.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd14ca54",
   "metadata": {},
   "source": [
    "Lastly, we can check that the results were indeed output into a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f07422f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"boxes\": [[[[21.58724594116211, 60.32127380371094, 33.97724151611328, 75.53152465820312, 108.71205139160156, 62.45012664794922], [29.138856887817383, 57.99709701538086, 45.1968994140625, 66.86248779296875, 83.99801635742188, 66.1964111328125], [21.605960845947266, 48.43174743652344, 49.73490524291992, 75.6953125, 96.08973693847656, 78.13142395019531], [35.06386947631836, 68.13758087158203, 40.05929183959961, 60.62265396118164, 100.37023162841797, 56.25345230102539], [45.2677001953125, 71.50562286376953, 45.317298889160156, 82.5245361328125, 97.23815155029297, 66.2081527709961], [28.44527244567871, 57.32223892211914, 29.66332244873047, 66.66019439697266, 83.91702270507812, 51.12281036376953], [0.0, 14.650421142578125, 20.98767852783203, 38.73200607299805, 76.86129760742188, 43.37999725341797], [0.0, 43.802040100097656, 18.751644134521484, 31.445295333862305, 60.979209899902344, 43.825016021728516]]]], \"classes\": [[[0, 0, 0, 0, 0, 0, 0, 0]]], \"scores\": [[[0.28776782751083374, 0.09653531759977341, 0.07356304675340652, 0.03138042986392975, 0.026810195297002792, 0.022586042061448097, 0.02136888913810253, 0.020567094907164574]]]}"
     ]
    }
   ],
   "source": [
    "!cat output/output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca8931",
   "metadata": {},
   "source": [
    "# Wrapping it all up\n",
    "Next, we take cells 1, 2, and 3, and paste them into a file called spleen_detector_monaideploy.py. This is done in the next cell.\n",
    "At the end, we add the `if __name__ == \"__main__\":` definition to make sure that the app is run if it's called on the python command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16783942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting spleen_detector_monaideploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile spleen_detector_monaideploy.py\n",
    "\n",
    "# Cell [1]\n",
    "import monai.deploy.core as md  # 'md' stands for MONAI Deploy (or can use 'core' instead)\n",
    "from monai.deploy.core import (\n",
    "    Application,\n",
    "    DataPath,\n",
    "    ExecutionContext,\n",
    "    InputContext,\n",
    "    IOType,\n",
    "    Operator,\n",
    "    OutputContext,\n",
    ")\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    BoundingRectd,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    Lambdad,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.apps.detection.utils.anchor_utils import AnchorGeneratorWithAnchorShape\n",
    "from monai.apps.detection.metrics.coco import COCOMetric\n",
    "from monai.apps.detection.metrics.matching import matching_batch\n",
    "from monai.apps.detection.networks.retinanet_detector import RetinaNetDetector\n",
    "from monai.apps.detection.networks.retinanet_network import (\n",
    "    RetinaNet,\n",
    "    resnet_fpn_feature_extractor,\n",
    ")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "# Cell [2]\n",
    "@md.input(\"image\", DataPath, IOType.DISK)\n",
    "@md.output(\"output\", DataPath, IOType.DISK)\n",
    "@md.env(pip_packages=[\"monai\"])\n",
    "class SpleenDetectorOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\"\"\"\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        test_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image\"]),\n",
    "                EnsureChannelFirstd(keys=[\"image\"]),\n",
    "                EnsureTyped(keys=[\"image\"], dtype=torch.float32),\n",
    "                ScaleIntensityRanged(\n",
    "                    keys=[\"image\"], a_min=-57, a_max=164,\n",
    "                    b_min=0.0, b_max=1.0, clip=True,\n",
    "                ),\n",
    "                CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
    "                Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "                Spacingd(keys=[\"image\"], pixdim=(\n",
    "                    1.5, 1.5, 2.0), mode=(\"bilinear\")),\n",
    "            ]\n",
    "        )\n",
    "        return test_transforms\n",
    "\n",
    "    def compute(self, op_input: InputContext, op_output: OutputContext, context: ExecutionContext):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "        \n",
    "        input_path = op_input.get().path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image_tensor = self.transform({\"image\": input_path})  # Load path as dict\n",
    "        image_tensor = torch.tensor(image_tensor[\"image\"].array)  # Get just the image for input\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = [image_tensor.to(device)]\n",
    "\n",
    "        ### Build Anchor Generator\n",
    "        anchor_generator = AnchorGeneratorWithAnchorShape(\n",
    "            feature_map_scales=[2**l for l in range(len([1,2]) + 1)],\n",
    "            base_anchor_shapes=[[6,8,4],[8,6,5],[10,10,6]],\n",
    "        )\n",
    "        \n",
    "        ### Build Model\n",
    "        model = context.models.get()  # get a TorchScriptModel object\n",
    "        model.predictor = torch.jit.load(model.path, map_location=device).eval()\n",
    "        net = model.predictor\n",
    "        \n",
    "        ### Build Detector\n",
    "        detector = RetinaNetDetector(\n",
    "            network=net, anchor_generator=anchor_generator, debug=False\n",
    "        ).to(device)\n",
    "\n",
    "        detector.set_target_keys(box_key=\"label_box\", label_key=\"label_class\")\n",
    "\n",
    "        # set validation components\n",
    "        detector.set_box_selector_parameters(\n",
    "            score_thresh=0.02,\n",
    "            topk_candidates_per_level=1000,\n",
    "            nms_thresh=0.22,\n",
    "            detections_per_img=100,\n",
    "        )\n",
    "        detector.set_sliding_window_inferer(\n",
    "            roi_size=[512,512,208],\n",
    "            overlap=0.25,\n",
    "            sw_batch_size=1,\n",
    "            mode=\"constant\",\n",
    "            device=\"cpu\",\n",
    "        )\n",
    "        \n",
    "        detector.eval()\n",
    "        with torch.no_grad():\n",
    "            with torch.cuda.amp.autocast():\n",
    "                val_outputs_all = detector(image_tensor, use_inferer=True)\n",
    "\n",
    "        pred_boxes=[\n",
    "            val_data_i[detector.target_box_key].cpu().detach().numpy().tolist()\n",
    "            for val_data_i in val_outputs_all\n",
    "        ],\n",
    "        pred_classes=[\n",
    "            val_data_i[detector.target_label_key].cpu().detach().numpy().tolist()\n",
    "            for val_data_i in val_outputs_all\n",
    "        ],\n",
    "        pred_scores=[\n",
    "            val_data_i[detector.pred_score_key].cpu().detach().numpy().tolist()\n",
    "            for val_data_i in val_outputs_all\n",
    "        ],\n",
    "        print(pred_boxes, pred_classes, pred_scores)\n",
    "        result = {\"boxes\": pred_boxes, \"classes\": pred_classes, \"scores\": pred_scores}\n",
    "\n",
    "        # Get output (folder) path and create the folder if not exists\n",
    "        output_folder = op_output.get().path\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Write result to \"output.json\"\n",
    "        output_path = output_folder / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "            \n",
    "# Cell [3]\n",
    "@md.resource(cpu=1, gpu=1, memory=\"6Gi\")\n",
    "class App(Application):\n",
    "    \"\"\"Application class for the Spleen detector.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        classifier_op = SpleenDetectorOperator()\n",
    "\n",
    "        self.add_operator(classifier_op)\n",
    "\n",
    "# Finally\n",
    "if __name__ == \"__main__\":\n",
    "    App(do_run=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388c976",
   "metadata": {},
   "source": [
    "# Free Memory\n",
    "This previous test takes a lot of memory and the next section won't run if the memory isn't freed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0decd758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test input file path: ./Task09_Spleen/imagesTs/spleen_1.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "root_dir = \"./\"\n",
    "data_dir = os.path.join(root_dir, \"Task09_Spleen\")\n",
    "test_images = sorted(\n",
    "    glob.glob(os.path.join(data_dir, \"imagesTs\", \"*.nii.gz\")))\n",
    "data_dicts = [\n",
    "    {\"image\": image_name}\n",
    "    for image_name in test_images\n",
    "]\n",
    "test_input_path = data_dicts[0][\"image\"]\n",
    "print(f\"Test input file path: {test_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8aca51",
   "metadata": {},
   "source": [
    "# Use PYTHON to run the code directly\n",
    "Now that the code is written, we can then run the code using python directly as a test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb86a079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mGoing to initiate execution of operator SpleenDetectorOperator\u001b[39m\n",
      "\u001b[32mExecuting operator SpleenDetectorOperator \u001b[33m(Process ID: 6697, Operator ID: 9acb4191-b4dc-4c22-ae7e-bf2d507bc3cf)\u001b[39m\n",
      "([[[21.58724594116211, 60.32127380371094, 33.97724151611328, 75.53152465820312, 108.71205139160156, 62.45012664794922], [29.138856887817383, 57.99709701538086, 45.1968994140625, 66.86248779296875, 83.99801635742188, 66.1964111328125], [21.605960845947266, 48.43174743652344, 49.73490524291992, 75.6953125, 96.08973693847656, 78.13142395019531], [35.06386947631836, 68.13758087158203, 40.05929183959961, 60.62265396118164, 100.37023162841797, 56.25345230102539], [45.2677001953125, 71.50562286376953, 45.317298889160156, 82.5245361328125, 97.23815155029297, 66.2081527709961], [28.44527244567871, 57.32223892211914, 29.66332244873047, 66.66019439697266, 83.91702270507812, 51.12281036376953], [0.0, 14.650421142578125, 20.98767852783203, 38.73200607299805, 76.86129760742188, 43.37999725341797], [0.0, 43.802040100097656, 18.751644134521484, 31.445295333862305, 60.979209899902344, 43.825016021728516]]],) ([[0, 0, 0, 0, 0, 0, 0, 0]],) ([[0.28776782751083374, 0.09653531759977341, 0.07356304675340652, 0.03138042986392975, 0.026810195297002792, 0.022586042061448097, 0.02136888913810253, 0.020567094907164574]],)\n",
      "\u001b[34mDone performing execution of operator SpleenDetectorOperator\n",
      "\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!python spleen_detector_monaideploy.py -i {test_input_path} -o output -m classifier.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f423ad58",
   "metadata": {},
   "source": [
    "# Use MONAI Deploy Runner to test the app\n",
    "We can also test the execution using the included MONAI deploy runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5633f2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mGoing to initiate execution of operator SpleenDetectorOperator\u001b[39m\n",
      "\u001b[32mExecuting operator SpleenDetectorOperator \u001b[33m(Process ID: 6908, Operator ID: dfa85890-dcf4-4a66-984b-f67a587c7e88)\u001b[39m\n",
      "([[[21.58724594116211, 60.32127380371094, 33.97724151611328, 75.53152465820312, 108.71205139160156, 62.45012664794922], [29.138856887817383, 57.99709701538086, 45.1968994140625, 66.86248779296875, 83.99801635742188, 66.1964111328125], [21.605960845947266, 48.43174743652344, 49.73490524291992, 75.6953125, 96.08973693847656, 78.13142395019531], [35.06386947631836, 68.13758087158203, 40.05929183959961, 60.62265396118164, 100.37023162841797, 56.25345230102539], [45.2677001953125, 71.50562286376953, 45.317298889160156, 82.5245361328125, 97.23815155029297, 66.2081527709961], [28.44527244567871, 57.32223892211914, 29.66332244873047, 66.66019439697266, 83.91702270507812, 51.12281036376953], [0.0, 14.650421142578125, 20.98767852783203, 38.73200607299805, 76.86129760742188, 43.37999725341797], [0.0, 43.802040100097656, 18.751644134521484, 31.445295333862305, 60.979209899902344, 43.825016021728516]]],) ([[0, 0, 0, 0, 0, 0, 0, 0]],) ([[0.28776782751083374, 0.09653531759977341, 0.07356304675340652, 0.03138042986392975, 0.026810195297002792, 0.022586042061448097, 0.02136888913810253, 0.020567094907164574]],)\n",
      "\u001b[34mDone performing execution of operator SpleenDetectorOperator\n",
      "\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "!monai-deploy exec spleen_detector_monaideploy.py -i {test_input_path} -o output -m classifier.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88400aad",
   "metadata": {},
   "source": [
    "# Package App for Docker\n",
    "Lastly, this step will call docker to package the application as a docker image which can then be run anywhere that docker images are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e30b3615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building MONAI Application Package... /bin/bash: docker: command not found\n",
      "\bDone\n"
     ]
    }
   ],
   "source": [
    "!monai-deploy package spleen_detector_monaideploy.py --tag spleen_detect_app:latest --model classifier.zip  # -l DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb5710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
